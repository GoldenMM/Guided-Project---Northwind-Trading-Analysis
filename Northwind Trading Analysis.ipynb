{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Northwind Traders Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 146, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3304, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 449, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 1263, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 712, in checkout\n",
      "    rec = pool._do_get()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 179, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    return self._create_connection()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 390, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 674, in __init__\n",
      "    self.__connect()\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 900, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 896, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/create.py\", line 643, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/default.py\", line 617, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/psycopg2/__init__.py\", line 122, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "psycopg2.OperationalError: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sql/connection.py\", line 70, in set\n",
      "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sql/connection.py\", line 55, in __init__\n",
      "    self.internal_connection = engine.connect()\n",
      "                               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3280, in connect\n",
      "    return self._connection_cls(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 148, in __init__\n",
      "    Connection._handle_dbapi_exception_noconnection(\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 2444, in _handle_dbapi_exception_noconnection\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 146, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3304, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 449, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 1263, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 712, in checkout\n",
      "    rec = pool._do_get()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 179, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    return self._create_connection()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 390, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 674, in __init__\n",
      "    self.__connect()\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 900, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 896, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/create.py\", line 643, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sqlalchemy/engine/default.py\", line 617, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xerxes/.pyenv/versions/3.12.2/lib/python3.12/site-packages/psycopg2/__init__.py\", line 122, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# Connection info for code readability\n",
    "conn_info = {\n",
    "    'dbname': 'northwind',\n",
    "    'user': 'postgres',\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Load the SQL extension\n",
    "%load_ext sql\n",
    "%sql postgresql://postgres:{conn_info['password']}@localhost/northwind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll be acting as a data analyst for the North Wind Traders Company, a gourmet food distributor. Management has asked us to generate some SQL queries with our database in order to make strategic decisions about the business. We will be evaluating the company in the following four categories: \n",
    "\n",
    "- Evaluating employee performance to boost productivity.\n",
    "- Analyzing sales growth to identify trends, monitor company progress, and make more accurate forecasts.\n",
    "- And evaluating customer purchase behavior to target high-value customers with promotional incentives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Employee Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating employee performance, we want to find both the top performers so we know who deserves a bonus and the bottom performers so we know which employees require additional training and resources.\n",
    "\n",
    "The employees are within sales role so an obvious metric is to track total sales for each employee. This is not sufficient as different employees have different start dates which skews the data.\n",
    "\n",
    "The other goal is to track not only which employees required additional training, but also in which areas they are under performing (sales amount, sales volume, consistency).\n",
    "\n",
    "We would also like to be able to track these metrics over time to find which employees show improvement to offer a bonus as incentive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining performance metrics\n",
    "Below we have a rudimentary ranking of the employees at the company. This give a general idea of the ranking of the employees but it is too general to be used for anything other than simple guide to who should receive a bonus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH employee_sales AS (\n",
    "    SELECT  e.employee_id, e.first_name || ' ' || e.last_name AS employee_name,\n",
    "            SUM(od.quantity * od.unit_price) AS total_sales,\n",
    "            COUNT(DISTINCT o.order_id) AS order_count,\n",
    "            e.hire_date\n",
    "            \n",
    "    FROM employees e\n",
    "    JOIN orders o ON e.employee_id = o.employee_id\n",
    "    JOIN order_details od ON o.order_id = od.order_id\n",
    "    GROUP BY e.employee_id\n",
    ")\n",
    "\n",
    "SELECT  employee_name, ROUND(total_sales::DECIMAL, 2) as total_sales,\n",
    "        RANK() OVER(ORDER BY total_sales DESC) AS sales_rank,\n",
    "        order_count\n",
    "FROM    employee_sales;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform this data to track three performance metrics for each employee every month.\n",
    "- Order count: How many sales were made.\n",
    "- Total amount: The total sales for that month. This will be the main determiner of high performance bonuses.\n",
    "- Average order value: This helps us track which employees can sell the 'big ticket' items.\n",
    "\n",
    "There will also be a table which is aggregate average of all of these metrics. This will let us not only see which employees are improving or stagnating, but also allow us track employee consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get the metrics for each employee by month\n",
    "query = \"\"\"\n",
    "WITH employee_sales AS (\n",
    "    SELECT  e.employee_id, e.first_name || ' ' || e.last_name AS employee_name,\n",
    "            SUM(od.quantity * od.unit_price) AS total_sales,\n",
    "            EXTRACT(YEAR FROM o.order_date) AS order_year,\n",
    "            EXTRACT(MONTH FROM o.order_date) AS order_month,\n",
    "            COUNT(DISTINCT o.order_id) AS order_count\n",
    "            \n",
    "    FROM employees e\n",
    "    JOIN orders o ON e.employee_id = o.employee_id\n",
    "    JOIN order_details od ON o.order_id = od.order_id\n",
    "    GROUP BY e.employee_id, order_year, order_month\n",
    ")\n",
    "SELECT  employee_name, TO_DATE(order_year || '-' || order_month, 'YYYY-MM') AS order_date, \n",
    "        ROUND(total_sales::DECIMAL, 2) AS total_sales,\n",
    "        order_count,\n",
    "        ROUND((total_sales/order_count)::DECIMAL, 2) AS avg_order_amount     \n",
    "FROM   employee_sales\n",
    "\"\"\"\n",
    "\n",
    "with psycopg2.connect(**conn_info) as conn:\n",
    "    employee_metrics_by_month = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a separate dataframe for each employee\n",
    "employees = employee_metrics_by_month['employee_name'].unique()\n",
    "employee_data = {employee: employee_metrics_by_month[employee_metrics_by_month['employee_name'] == employee].copy() for employee in employees}\n",
    "\n",
    "#Add an 'employee' who is the average of all employees fo comparison\n",
    "employee_data['Average'] = employee_metrics_by_month.pivot_table(index='order_date', values=['total_sales', 'order_count', 'avg_order_amount'], aggfunc='mean').reset_index()\n",
    "\n",
    "# Create a moving average for each employee\n",
    "for employee, data in employee_data.items():\n",
    "    data['total_sales_rolling'] = data['total_sales'].copy().rolling(window=3).mean()\n",
    "    data['order_count_rolling'] = data['order_count'].copy().rolling(window=3).mean()\n",
    "    data['avg_order_amount_rolling'] = data['avg_order_amount'].copy().rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 20))\n",
    "for employee, data in employee_data.items():\n",
    "    axs[0].plot(data['order_date'], data['total_sales_rolling'], label=employee)\n",
    "    axs[1].plot(data['order_date'], data['avg_order_amount_rolling'], label=employee)\n",
    "    axs[2].plot(data['order_date'], data['order_count_rolling'], label=employee)\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Date')\n",
    "\n",
    "# Legend\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[1].legend(loc='upper left')\n",
    "axs[2].legend(loc='upper left')\n",
    "\n",
    "# Set title for each subplot\n",
    "axs[0].set_title('Total Sales')\n",
    "axs[1].set_title('Average Order Amount')\n",
    "axs[2].set_title('Order Count')\n",
    "plt.subplots_adjust(hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between the metrics for each employee\n",
    "employee_metrics_by_month.pivot_table(index='employee_name', values=['total_sales', 'order_count', 'avg_order_amount'], aggfunc='mean').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average values for each employee\n",
    "employee_metrics_by_month.pivot_table(index='employee_name', values=['total_sales', 'order_count', 'avg_order_amount'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several takeaways from the above graphs.\n",
    "1. Average order amount seems to have high variance across all time periods and employees, meaning it is a metric highly dependent on chance and thus not a good metric to determine employee effectiveness.\n",
    "2. The order amount has a strong correlation with total sales (*r=0.93*) and hence is a good metric for determining the effectiveness of an employee and thus should be the metric we most want to encourage in the employees.\n",
    "3. While average order amount has high variance, it still correlates with total sales with value of *r=0.33* and should also rewarded, albeit to a lesser degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Total of Monthly Sales\n",
    "Now that we have some useful insight on individual employee performance, we can look at changes that are more macroscopic level. Let's start by creating a running total of monthly sales to track the companies progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH monthly_sales AS (\n",
    "    SELECT  DATE_TRUNC('month', o.order_date) AS month,\n",
    "            SUM(od.quantity * od.unit_price) AS total_sales\n",
    "    FROM orders o\n",
    "    JOIN order_details od ON o.order_id = od.order_id\n",
    "    GROUP BY month\n",
    ")\n",
    "\n",
    "SELECT  month,\n",
    "        ROUND(total_sales::numeric, 2),\n",
    "        ROUND(SUM(total_sales) OVER(ORDER BY month\n",
    "                                    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)::numeric, 2) AS running_total\n",
    "FROM monthly_sales;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month by Month Sale Growth\n",
    "It would be useful to see these month by month sales figures as represented in the change between each month. To do this, we're going to calculate the percentage change each month as compared to its previous month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH monthly_sales AS (\n",
    "    SELECT  DATE_TRUNC('month', o.order_date) AS month,\n",
    "            SUM(od.quantity * od.unit_price) AS total_sales\n",
    "    FROM orders o\n",
    "    JOIN order_details od ON o.order_id = od.order_id\n",
    "    GROUP BY month\n",
    "),\n",
    "monthly_sales_change AS (\n",
    "    SELECT  month,\n",
    "            total_sales,\n",
    "            LAG(total_sales) OVER(ORDER BY month) AS last_month_sales\n",
    "    FROM monthly_sales\n",
    ")\n",
    "\n",
    "SELECT  month,\n",
    "        '$' || ROUND(total_sales::numeric, 2) AS total_sales,\n",
    "        ROUND(((total_sales - last_month_sales) / last_month_sales * 100)::numeric, 2) || '%' AS sales_growth_pct\n",
    "FROM monthly_sales_change;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying High Value Customers\n",
    "Now let's change our attention to a different aspect of the business: the customers. We want to identify the top 10 customers that are considered 'high value' in order to target particular promotions and specials towards them. We define 'high value' by the percentage of orders that customer makes that are above the average order value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH\n",
    "customer_sales AS (\n",
    "    SELECT  c.customer_id,\n",
    "            c.company_name,\n",
    "            od.quantity * od.unit_price AS sale_total,\n",
    "            AVG(od.quantity * od.unit_price) OVER() AS avg_sale_total,\n",
    "            CASE\n",
    "                WHEN (od.quantity * od.unit_price) > (AVG(od.quantity * od.unit_price) OVER())\n",
    "                    THEN 'High'\n",
    "                ELSE 'Low'\n",
    "            END AS sale_category\n",
    "    FROM customers c\n",
    "    JOIN orders o ON c.customer_id = o.customer_id\n",
    "    JOIN order_details od ON o.order_id = od.order_id\n",
    ")\n",
    "\n",
    "SELECT  company_name,\n",
    "        (COUNT(sale_category) FILTER(WHERE sale_category = 'High') * 100 / COUNT(sale_category))::numeric AS high_sale_pct\n",
    "FROM customer_sales\n",
    "GROUP BY company_name\n",
    "ORDER BY high_sale_pct DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Percentage of Sales for each Category\n",
    "Now let's look at each category of our products to determine what percentage of our sales that category takes up. This will help us to determine which category of products we should be putting more effort into marketing and also help and also help inform our decisions on inventory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH category_sales AS\n",
    "(SELECT c.category_name,\n",
    "        SUM(od.quantity * od.unit_price) AS total_sales\n",
    "    FROM categories c\n",
    "    JOIN products p ON c.category_id = p.category_id\n",
    "    JOIN order_details od ON p.product_id = od.product_id\n",
    "    GROUP BY c.category_name\n",
    ")\n",
    "\n",
    "SELECT  category_name,\n",
    "        ROUND((total_sales / SUM(total_sales) OVER())::numeric * 100, 2) || '%' AS sales_pct\n",
    "FROM category_sales\n",
    "ORDER BY total_sales DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Products in each Category\n",
    "Now let's drill down a bit further into the product performance. Let's find the top three products in terms of sales for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH product_sales AS \n",
    "(SELECT p.product_name,\n",
    "        c.category_name,\n",
    "        SUM(od.quantity * od.unit_price) AS total_sales\n",
    "    FROM products p\n",
    "    JOIN order_details od ON p.product_id = od.product_id\n",
    "    JOIN categories c ON p.category_id = c.category_id\n",
    "    GROUP BY p.product_name, c.category_name\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM (SELECT  product_name,\n",
    "            category_name,\n",
    "            ROW_NUMBER() OVER(PARTITION BY category_name\n",
    "                              ORDER BY total_sales DESC) AS sales_rank\n",
    "        FROM product_sales) AS ranked_products\n",
    "WHERE sales_rank <= 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
